{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0       1         2        3         4  5     6        7       8  9\n",
      "0       1    0.00  0.272030  1.00820 -0.082102  1 -63.5  2.42520  924.25  1\n",
      "1       1    0.50  0.272030  1.00820 -0.082102  1 -63.0  4.73690  921.75  1\n",
      "2       1    1.50  0.447910  0.91636 -0.013684  1 -63.5  3.03110  923.75  1\n",
      "3       1    1.75  0.447910  0.91636 -0.013684  1 -63.0  2.03710  921.25  1\n",
      "4       1    2.50  0.342380  0.96229 -0.059296  1 -63.5  5.89200  920.25  1\n",
      "5       1    3.25  0.342380  0.96229 -0.059296  4 -56.5  1.25630  924.75  1\n",
      "6       1    4.00  0.307210  0.99674 -0.070699  1 -63.5  3.87180  922.75  1\n",
      "7       1    5.00  0.272030  0.99674 -0.093505  1 -64.0  2.49430  924.25  1\n",
      "8       1    5.50  0.236850  1.03120 -0.127710  1 -64.5  2.00800  924.75  1\n",
      "9       1    6.00  0.236850  1.03120 -0.127710  1 -66.0  1.19040  925.75  1\n",
      "10      1    6.50  0.236850  1.03120 -0.127710  1 -63.0  0.61206  922.75  1\n",
      "11      1    6.75  0.236850  1.03120 -0.127710  1 -65.0  1.65060  925.25  1\n",
      "12      1    7.75  0.318930  0.99674 -0.070699  1 -62.0  4.80750  921.75  1\n",
      "13      1    8.00  0.318930  0.99674 -0.070699  4 -56.5  4.52520  924.75  1\n",
      "14      1    9.00  0.471360  0.92784 -0.002281  1 -62.5  3.81350  922.75  1\n",
      "15      1    9.75  0.401010  0.93932 -0.025087  1 -64.0  2.41300  924.25  1\n",
      "16      1   10.00  0.401010  0.93932 -0.025087  1 -62.5  1.53090  921.75  1\n",
      "17      1   10.50  0.401010  0.93932 -0.025087  1 -64.5  5.22470  924.75  1\n",
      "18      1   10.75  0.401010  0.93932 -0.025087  4 -58.0  0.50468  925.75  1\n",
      "19      1   12.00  0.307210  0.99674 -0.070699  1 -64.0  2.46200  924.25  1\n",
      "20      1   12.50  0.307210  0.99674 -0.070699  1 -63.0  5.90890  920.25  1\n",
      "21      1   13.00  0.307210  0.99674 -0.070699  1 -64.0  1.99260  924.75  1\n",
      "22      1   14.00  0.412730  0.93932 -0.002281  1 -62.0  1.92210  921.25  1\n",
      "23      1   15.25  0.272030  1.00820 -0.104910  4 -57.0  1.37140  924.75  1\n",
      "24      1   15.50  0.272030  1.00820 -0.104910  1 -62.0  1.08450  922.25  1\n",
      "25      1   16.50  0.248580  1.03120 -0.093505  1 -65.0  4.56970  925.25  1\n",
      "26      1   17.50  0.260300  1.01970 -0.104910  1 -62.5  1.50640  921.75  1\n",
      "27      1   18.50  0.318930  0.99674 -0.070699  1 -64.0  5.99630  923.75  1\n",
      "28      1   18.75  0.318930  0.99674 -0.070699  1 -62.0  1.92050  921.25  1\n",
      "29      1   19.25  0.318930  0.99674 -0.070699  1 -62.5  2.27640  920.75  1\n",
      "...    ..     ...       ...      ...       ... ..   ...      ...     ... ..\n",
      "52452  60  477.50  1.010700  0.23885 -0.082102  4 -63.0  1.44500  920.25  3\n",
      "52453  60  477.75  0.963830  0.30775 -0.082102  4 -62.5  5.94880  921.75  3\n",
      "52454  60  478.00  0.963830  0.30775 -0.082102  4 -62.5  1.14900  923.25  3\n",
      "52455  60  478.50  0.893480  0.45703 -0.196130  4 -65.5  0.84676  925.75  1\n",
      "52456  60  478.75  0.963830  0.49148 -0.207540  4 -63.0  0.20095  922.75  1\n",
      "52457  60  479.25  1.069400  0.42258 -0.173330  4 -64.0  1.15360  921.25  1\n",
      "52458  60  479.75  1.163200  0.45703 -0.196130  3 -56.0  4.44240  924.25  1\n",
      "52459  60  479.85  1.163200  0.45703 -0.196130  3 -56.5  4.50070  924.25  1\n",
      "52460  60  480.25  0.893480  0.60631 -0.321570  1 -59.0  2.47430  921.75  1\n",
      "52461  60  480.50  0.893480  0.60631 -0.321570  3 -56.5  5.02990  923.25  1\n",
      "52462  60  480.75  0.893480  0.60631 -0.321570  4 -65.5  1.85150  922.25  1\n",
      "52463  60  481.25  0.893480  0.60631 -0.321570  1 -57.5  0.70256  923.75  1\n",
      "52464  60  481.50  0.893480  0.60631 -0.321570  1 -57.0  2.16900  922.75  1\n",
      "52465  60  481.75  0.834850  0.67521 -0.196130  4 -64.5  4.84430  925.25  1\n",
      "52466  60  482.00  0.834850  0.67521 -0.196130  4 -61.0  4.07120  920.75  1\n",
      "52467  60  482.25  0.834850  0.67521 -0.196130  3 -58.0  0.23163  924.25  1\n",
      "52468  60  482.50  0.834850  0.67521 -0.196130  1 -56.5  5.37970  920.25  1\n",
      "52469  60  482.60  0.834850  0.67521 -0.196130  1 -56.5  1.77170  921.75  1\n",
      "52470  60  482.75  0.834850  0.67521 -0.196130  1 -57.0  4.73850  923.25  1\n",
      "52471  60  483.25  0.377560  0.98526 -0.150520  3 -58.5  1.01090  922.25  1\n",
      "52472  60  483.50  0.377560  0.98526 -0.150520  1 -56.5  4.68020  923.75  1\n",
      "52473  60  483.75  0.377560  0.98526 -0.150520  4 -62.0  5.70330  922.75  1\n",
      "52474  60  484.00  0.377560  0.98526 -0.150520  1 -56.5  0.35282  921.25  1\n",
      "52475  60  484.50  0.330660  0.95081 -0.230340  3 -58.0  4.87650  920.75  1\n",
      "52476  60  484.75  0.330660  0.95081 -0.230340  3 -57.5  5.16640  920.25  1\n",
      "52477  60  485.00  0.330660  0.95081 -0.230340  1 -57.0  6.21880  921.75  1\n",
      "52478  60  485.08  0.330660  0.95081 -0.230340  3 -58.0  0.88050  921.75  1\n",
      "52479  60  485.50  0.330660  0.95081 -0.230340  1 -60.5  5.00540  924.75  1\n",
      "52480  60  488.25  0.119600  0.82449  0.009122  4 -56.0  4.90870  925.75  4\n",
      "52481  60  488.75  0.072698  1.31830  0.009122  4 -56.5  1.03700  922.75  4\n",
      "\n",
      "[52482 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('/Users/Jos√© Diogo/Documents/GitHub/Trabalho-IART/Trabalho_2/test_file_S1.txt', header = None)\n",
    "print(dataset)\n",
    "X = dataset.iloc[:, 0:9]\n",
    "y = dataset.iloc[:, 9]\n",
    "X_train, X_test, y_train, y_test= train_test_split(X,y, random_state=0, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:, 0:9]\n",
    "y = dataset.iloc[:, 9]\n",
    "X_train, X_test, y_train, y_test= train_test_split(X,y, random_state=0, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='euclidean',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=7, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#n_neighbors=sqrt(n), n=60, sqrt(60)=7.7, 7 is odd\n",
    "classifier = KNeighborsClassifier(n_neighbors=7, p=2, metric='euclidean')\n",
    "\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "#KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='euclidean', metric_params=None, n_jobs=1, n_neighbors=7, p=2, weights='uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3471   54  276   18]\n",
      " [ 125  904  103    3]\n",
      " [ 176   30 7450   12]\n",
      " [  67   27   57  348]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Target is multiclass but average='binary'. Please choose another average setting.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-ec485cdc4e2d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36mf1_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[0;32m    718\u001b[0m     return fbeta_score(y_true, y_pred, 1, labels=labels,\n\u001b[0;32m    719\u001b[0m                        \u001b[0mpos_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 720\u001b[1;33m                        sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    721\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    722\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[0;32m    832\u001b[0m                                                  \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    833\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'f-score'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 834\u001b[1;33m                                                  sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    835\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    836\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight)\u001b[0m\n\u001b[0;32m   1045\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1046\u001b[0m             raise ValueError(\"Target is %s but average='binary'. Please \"\n\u001b[1;32m-> 1047\u001b[1;33m                              \"choose another average setting.\" % y_type)\n\u001b[0m\u001b[0;32m   1048\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mpos_label\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1049\u001b[0m         warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n",
      "\u001b[1;31mValueError\u001b[0m: Target is multiclass but average='binary'. Please choose another average setting."
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "\n",
    "print(f1_score(y_test, y_pred))\n",
    "print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
