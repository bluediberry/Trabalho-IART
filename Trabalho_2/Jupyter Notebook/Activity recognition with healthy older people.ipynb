{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import tensorflow\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Reshape\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-f0ba86add063>, line 12)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-f0ba86add063>\"\u001b[0;36m, line \u001b[0;32m12\u001b[0m\n\u001b[0;31m    TIME_PERIODS =\u001b[0m\n\u001b[0m                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Set some standard parameters upfront\n",
    "pd.options.display.float_format = '{:.1f}'.format\n",
    "sns.set() # Default seaborn look and feel\n",
    "plt.style.use('ggplot')\n",
    "print('keras version ', keras.__version__)\n",
    "# Same labels will be reused throughout the program\n",
    "LABELS = ['[1]Sitting-on-Bed',\n",
    "          '[2]Sitting-on-Chair',\n",
    "          '[3]Lying-Down',\n",
    "          '[4]Ambulating']\n",
    "# The number of steps within one time segment\n",
    "TIME_PERIODS = \n",
    "# The steps to take from one segment to the next; if this value is equal to\n",
    "# TIME_PERIODS, then there is no overlap between the segments\n",
    "STEP_DISTANCE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file_path):\n",
    "    \n",
    "    pd.options.display.float_format = '{:,.4f}'.format\n",
    "\n",
    "    column_names = ['experiment-id',\n",
    "                    'time',\n",
    "                    'frontal-acceleration',\n",
    "                    'vertical-acceleration',\n",
    "                    'lateral-acceleration',\n",
    "                    'antenna-id',\n",
    "                    'RSSI',\n",
    "                    'phase',\n",
    "                    'frequency',\n",
    "                    'label']\n",
    "    \n",
    "    df = pd.read_csv(file_path,\n",
    "                     header=None,\n",
    "                     names=column_names)\n",
    "\n",
    "    # This is very important otherwise the model will not fit and loss\n",
    "    # will show up as NAN\n",
    "    df.dropna(axis=0, how='any', inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "def convert_to_float(x):\n",
    "\n",
    "    try:\n",
    "        return np.float(x)\n",
    "    except:\n",
    "        return np.nan\n",
    " \n",
    "def show_basic_dataframe_info(dataframe):\n",
    "\n",
    "    # Shape and how many rows and columns\n",
    "    print('Number of columns in the dataframe: %i' % (dataframe.shape[1]))\n",
    "    print('Number of rows in the dataframe: %i\\n' % (dataframe.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data set containing all the data\n",
    "\n",
    "df = read_data('/Users/Mariana/Desktop/test_file.txt')\n",
    "\n",
    "#Reading multiple files not working **--**\n",
    "#file_path = '/Users/Mariana/Desktop/S1_Dataset/'\n",
    "#read_files = glob.glob(os.path.join(file_path, '*.txt'))\n",
    "#np_array_values = []\n",
    "\n",
    "#for files in read_files:\n",
    "\n",
    "#    df = pd.read_csv(files, header=None, names=column_names)\n",
    "    \n",
    "#    df.dropna(axis=0, how='any', inplace=True)\n",
    "\n",
    "#    np_array_values.append(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe the data\n",
    "show_basic_dataframe_info(df)\n",
    "df.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'].value_counts().plot(kind='bar',\n",
    "                                   title='Training Examples by Activity Type')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "for i in LABELS:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Data into Training and Test Set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Differentiate between test set and training set\n",
    "df_test = df[df['experiment-id'] > 50]\n",
    "df_train = df[df['experiment-id'] <= 50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize features for training data set (values between 0 and 1)\n",
    "# Surpress warning for next 6 operation\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "df_train['frontal-acceleration'] = df_train['frontal-acceleration'] / df_train['frontal-acceleration'].max()\n",
    "df_train['vertical-acceleration'] = df_train['vertical-acceleration'] / df_train['vertical-acceleration'].max()\n",
    "df_train['lateral-acceleration'] = df_train['lateral-acceleration'] / df_train['lateral-acceleration'].max()\n",
    "df_train['lateral-acceleration'] = df_train['lateral-acceleration'] / df_train['lateral-acceleration'].max()\n",
    "df_train['RSSI'] = df_train['RSSI'] / df_train['RSSI'].max()\n",
    "df_train['phase'] = df_train['phase'] / df_train['phase'].max()\n",
    "df_train['frequency'] = df_train['frequency'] / df_train['frequency'].max()\n",
    "\n",
    "# Round numbers\n",
    "df_train = df_train.round({'frontal-acceleration': 4,\n",
    "                           'vertical-acceleration': 4,\n",
    "                           'lateral-acceleration': 4,\n",
    "                           'RSSI': 4,\n",
    "                           'phase': 4,\n",
    "                           'frequency': 4})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshape Data into Segments and Prepare for Keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_segments_and_labels(df, time_steps, step, label_name):\n",
    "\n",
    "    # x, y, z acceleration as features\n",
    "    N_FEATURES = 6\n",
    "    # Number of steps to advance in each iteration (for me, it should always\n",
    "    # be equal to the time_steps in order to have no overlap between segments)\n",
    "    # step = time_steps\n",
    "    segments = []\n",
    "    labels = []\n",
    "    for i in range(0, len(df) - time_steps, step):\n",
    "        fa = df['frontal-acceleration'].values[i: i + time_steps]\n",
    "        va = df['vertical-acceleration'].values[i: i + time_steps]\n",
    "        la = df['lateral-acceleration'].values[i: i + time_steps]\n",
    "        rs = df['RSSI'].values[i: i + time_steps]\n",
    "        ph = df['phase'].values[i: i + time_steps]\n",
    "        fr = df['frequency'].values[i: i + time_steps]\n",
    "\n",
    "        # Retrieve the most often used label in this segment\n",
    "        label = stats.mode(df[label_name][i: i + time_steps])[0][0]\n",
    "        segments.append([fa, va, la, rs, ph, fr])\n",
    "        labels.append(label)\n",
    "\n",
    "    # Bring the segments into a better shape\n",
    "    reshaped_segments = np.asarray(segments, dtype= np.float32).reshape(-1, time_steps, N_FEATURES)\n",
    "    labels = np.asarray(labels)\n",
    "\n",
    "    return reshaped_segments, labels\n",
    "\n",
    "LABEL = 'label'\n",
    "x_train, y_train = create_segments_and_labels(df_train,\n",
    "                                              TIME_PERIODS,\n",
    "                                              STEP_DISTANCE,\n",
    "                                              LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('x_train shape: ', x_train.shape)\n",
    "print(x_train.shape[0], 'training samples')\n",
    "print('y_train shape: ', y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set input & output dimensions\n",
    "num_time_periods = x_train.shape[1]\n",
    "num_sensors = x_train.shape[2]\n",
    "num_classes = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (num_time_periods*num_sensors)\n",
    "x_train = x_train.reshape(x_train.shape[0], input_shape)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('input_shape:', input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "y_train = y_train.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_hot = np_utils.to_categorical(y_train, num_classes)\n",
    "print('New y_train shape: ', y_train_hot.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Deep Neural Network Model in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_m = Sequential()\n",
    "# Remark: since coreml cannot accept vector shapes of complex shape like\n",
    "# [80,3] this workaround is used in order to reshape the vector internally\n",
    "# prior feeding it into the network\n",
    "\n",
    "model_m.add(Reshape((TIME_PERIODS, 3), \n",
    "                    input_shape=(input_shape,)))\n",
    "model_m.add(Dense(100, activation='relu'))\n",
    "model_m.add(Dense(100, activation='relu'))\n",
    "model_m.add(Dense(100, activation='relu'))\n",
    "model_m.add(Flatten())\n",
    "model_m.add(Dense(num_classes, activation='softmax'))\n",
    "print(model_m.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_metadata": {
   "author": "Nils Ackermann",
   "title": "Human Activity Recognition (HAR) Tutorial with Keras and CoreML"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
